# Go Concurrency: Complete Guide to Goroutines and Channels

## 1. Introduction to Goroutines

### What is a Scheduler?

The Go scheduler is a runtime component that manages the execution of goroutines. It decides when and where each goroutine runs, efficiently mapping many goroutines onto a smaller number of operating system (OS) threads.

The **scheduler** is the â€œbrainâ€ of the Go runtime. Its job is to **decide which goroutine runs, when it runs, and on which thread**.

Letâ€™s explain it very simply.


## What Does the Scheduler Actually Do?

When you write:

```go
go task1()
go task2()
go task3()
```

You just created **3 goroutines**.

Now the question is:

ğŸ‘‰ Who decides which one runs first?

ğŸ‘‰ What happens if one goroutine is waiting?

ğŸ‘‰ How are CPU cores used?

 **Answer: The Go Scheduler.**


## Scheduler Responsibilities

### 1. Put Goroutines in a Queue

When a goroutine is created, it does NOT run immediately.

It goes into a **run queue** inside a Processor (P).

```
Queue: [G1, G2, G3, G4]
```

The scheduler manages this queue.


### 2. Assign Goroutines to Threads

The scheduler gives goroutines to an available OS thread (M).

**Flow:**

```
Goroutine â†’ Processor Queue â†’ Thread executes it
```


### 3. Switch When One Blocks

Example:

```go
func slowTask() {
	time.Sleep(2 * time.Second)
}

func fastTask() {
	fmt.Println("Fast task done")
}
```

If `slowTask` is sleeping, the scheduler:

âœ… pauses it

âœ… picks another goroutine

âœ… keeps CPU busy

ğŸ‘‰ CPU never sits idle.



### 4. Prevent One Goroutine from Hogging the CPU

Imagine this bad function:

```go
func infiniteLoop() {
	for {
	}
}
```

Older systems could freeze here.

Modern Go scheduler is **preemptive**, meaning:

ğŸ‘‰ It can INTERRUPT this goroutine

ğŸ‘‰ Give time to others

This is called **fair scheduling**.


## Real Example Showing Scheduler Behavior

```go
package main

import (
	"fmt"
	"time"
)

func worker(id int) {
	for i := 0; i < 3; i++ {
		fmt.Println("Worker", id, "running")
		time.Sleep(300 * time.Millisecond)
	}
}

func main() {
	for i := 1; i <= 3; i++ {
		go worker(i)
	}

	time.Sleep(2 * time.Second)
}
```

### What the Scheduler Does Here:

Step-by-step:

1. Creates 3 goroutines.
2. Places them in the processor queue.
3. Runs Worker 1.
4. Worker 1 sleeps â†’ scheduler switches.
5. Runs Worker 2.
6. Worker 2 sleeps â†’ switch again.
7. Runs Worker 3.

It keeps rotating them very fast.

Output might look like:

```
Worker 1 running
Worker 2 running
Worker 3 running
Worker 1 running
Worker 2 running
```

Notice how they **interleave** â€” thatâ€™s the scheduler working.



## Think of the Scheduler Like a Traffic Police ğŸš¦

* Goroutines = cars
* CPU cores = roads
* Scheduler = traffic controller

It makes sure:

âœ… No road is blocked

âœ… Cars move efficiently

âœ… No car waits forever



## Extremely Important Idea

ğŸ‘‰ **Goroutines are NOT truly parallel unless you have multiple CPU cores.**

But thanks to the scheduler, they **feel parallel** because switching is extremely fast.


## One-Line Definition

ğŸ‘‰ **The Go scheduler distributes goroutines across threads and CPU cores to maximize performance and prevent blocking.**



## Super Simple Summary

The scheduler:

âœ… Chooses which goroutine runs

âœ… Switches when one blocks

âœ… Uses CPU cores efficiently

âœ… Balances workload

âœ… Prevents starvation

Without the schedulerâ€¦

ğŸ‘‰ Goroutines would just be functions with no execution strategy.

The scheduler is what makes Go concurrency powerful.


Go uses the **G-M-P model**:

* **G (Goroutine):** A lightweight function managed by the Go runtime.
* **M (Machine):** An OS thread.
* **P (Processor):** A logical processor that provides the context needed to run goroutines.

## G-M-P Model :


### Simple Analogy

Imagine a pizza restaurant:

* **G (Goroutine)** â†’ Customers placing orders
* **M (Machine / Thread)** â†’ Chefs cooking pizzas
* **P (Processor)** â†’ Kitchen stations with tools

Now how it works:

1. Customers (Goroutines) arrive with work.
2. Kitchen stations (P) organize the work.
3. Chefs (M) actually cook the pizzas.

ğŸ‘‰ A chef **cannot cook without a kitchen station (P)**.

ğŸ‘‰ A kitchen station assigns waiting customers to available chefs.

This is how Go runs thousands or even millions of goroutines using only a few OS threads.



## What Each Component Does

### G â€” Goroutine

* Lightweight task.
* Starts with very little memory (~2KB).
* Managed entirely by the Go runtime.

Example:

```go
go sayHello()
```


### M â€” Machine (OS Thread)

* Real thread created by the operating system.
* Executes goroutines.
* More expensive than goroutines.

You donâ€™t control M directly â€” Go manages it for you.



### P â€” Processor

* Holds a queue of goroutines ready to run.
* Required for an M to execute Go code.
* Number of P usually equals the number of CPU cores.

Check it:

```go
package main

import (
	"fmt"
	"runtime"
)

func main() {
	fmt.Println("CPU cores:", runtime.NumCPU())
	fmt.Println("GOMAXPROCS:", runtime.GOMAXPROCS(0))
}
```

`GOMAXPROCS` = how many goroutines can run **at the same time** (parallelism).



## How Scheduling Happens (Step-by-Step)

1. You create many goroutines.
2. They are placed into a queue inside a P.
3. An M picks a goroutine from that queue.
4. The goroutine runs.
5. If it blocks (for example, waiting for I/O), Go switches to another goroutine.

ğŸ‘‰ This switching is very fast because it happens in user space.


## Code Example Showing Concurrency

```go
package main

import (
	"fmt"
	"time"
)

func task(id int) {
	for i := 0; i < 3; i++ {
		fmt.Println("Task", id, "running")
		time.Sleep(500 * time.Millisecond)
	}
}

func main() {

	for i := 1; i <= 5; i++ {
		go task(i) // Creates multiple G (goroutines)
	}

	time.Sleep(3 * time.Second)
}
```

### What Happens Internally

* 5 goroutines are created â†’ **G**
* Go assigns them to available processors â†’ **P**
* OS threads execute them â†’ **M**
* When one sleeps, another runs.

Even if you only have **2 CPU cores**, Go smartly rotates goroutines so everything progresses smoothly.



## Important Concept: Concurrency vs Parallelism

### Concurrency

Multiple tasks **in progress**.

* One chef cooking multiple dishes by switching between them.

### Parallelism

Multiple tasks running **at the exact same time**.

ğŸ‘‰ Multiple chefs cooking simultaneously.

Control parallelism:

```go
runtime.GOMAXPROCS(2) // Use 2 CPU cores
```



## Why G-M-P Is Powerful

Without this model:

* Threads are heavy.
* Creating thousands would crash your system.

With Go:

* Millions of goroutines possible
* Automatic scheduling
* Efficient CPU usage
* Very fast context switching



## Super Short Summary

* **G** â†’ Work to do
* **P** â†’ Organizer / Scheduler
* **M** â†’ Worker thread

ğŸ‘‰ M needs P to run G.

ğŸ‘‰ Many G share a few M.

That is the secret behind Goâ€™s high-performance concurrency.

---

### How Goroutines Work

A goroutine is a function that runs concurrently with other functions. Unlike OS threads, goroutines are lightweight and require very little memory (typically a few KB of stack space that grows dynamically).

When a program starts, the main function runs in its own goroutine. Additional goroutines can be created easily using the `go` keyword.

### How Go Switches Between Goroutines

Go uses **cooperative and preemptive scheduling**:

* **Cooperative:** Goroutines yield control during blocking operations such as channel communication, I/O, or system calls.
* **Preemptive:** Modern Go versions allow the runtime to interrupt long-running goroutines to prevent starvation.

Context switching between goroutines is much cheaper than switching between OS threads because it happens in user space rather than kernel space.

### Difference Between Goroutines and Threads

| Feature           | Goroutines        | OS Threads       |
| ----------------- | ----------------- | ---------------- |
| Memory Usage      | Very small (KBs)  | Large (MBs)      |
| Creation Cost     | Cheap             | Expensive        |
| Managed By        | Go runtime        | Operating system |
| Context Switching | Fast              | Slower           |
| Scalability       | Millions possible | Limited          |

Goroutines enable highly scalable concurrent applications.

---

## 2. Creating and Running Goroutines

Creating a goroutine is simpleâ€”just place the `go` keyword before a function call.

```go
package main

import (
	"fmt"
	"time"
)

func printMessage() {
	fmt.Println("Hello from Goroutine!")
}

func main() {
	go printMessage()
	time.Sleep(time.Second) // Wait so goroutine can finish
}
```

A better way to wait for goroutines is using synchronization tools like **WaitGroups**, instead of `time.Sleep`.

Anonymous functions can also be run as goroutines:

```go
go func() {
	fmt.Println("Running anonymous goroutine")
}()
```

---

## 3. Synchronization with WaitGroups

A **WaitGroup** waits for a collection of goroutines to finish executing.

Key methods:

* `Add(n)` â†’ Number of goroutines to wait for
* `Done()` â†’ Called when a goroutine finishes
* `Wait()` â†’ Blocks until all goroutines complete

Example:

```go
package main

import (
	"fmt"
	"sync"
)

func worker(id int, wg *sync.WaitGroup) {
	defer wg.Done()
	fmt.Println("Worker", id, "finished")
}

func main() {
	var wg sync.WaitGroup

	for i := 1; i <= 3; i++ {
		wg.Add(1)
		go worker(i, &wg)
	}

	wg.Wait()
	fmt.Println("All workers completed")
}
```

Without WaitGroups, the main function might exit before goroutines complete.

---

## 4. Introduction to Channels

Channels are Goâ€™s way of allowing goroutines to communicate safely.

They provide:

* Data sharing without explicit locks
* Synchronization between goroutines
* Prevention of race conditions

Create a channel:

```go
ch := make(chan int)
```

Send data:

```go
ch <- 10
```

Receive data:

```go
value := <-ch
```

Channels enforce synchronizationâ€”sending blocks until another goroutine receives.

---

## 5. Unbuffered Channels vs Buffered Channels

### Unbuffered Channels

Have no capacity. Sending blocks until a receiver is ready.

```go
ch := make(chan int)
```

Behavior:

* Guarantees sender and receiver meet at the same time.
* Useful when you need strict synchronization.

Example:

```go
go func() {
	ch <- 5
}()

fmt.Println(<-ch)
```

### Buffered Channels

Allow sending multiple values without immediate receiving.

```go
ch := make(chan int, 3)
```

Behavior:

* Sender blocks only when buffer is full.
* Receiver blocks when buffer is empty.

Example:

```go
ch := make(chan string, 2)

ch <- "Hello"
ch <- "Go"

fmt.Println(<-ch)
fmt.Println(<-ch)
```

### Key Difference

| Feature  | Unbuffered      | Buffered          |
| -------- | --------------- | ----------------- |
| Capacity | 0               | >0                |
| Blocking | Immediate       | When full/empty   |
| Use Case | Synchronization | Queues, pipelines |

---

## 6. Channel Operations: Sending and Receiving Data

### Sending

```go
ch <- value
```

### Receiving

```go
value := <-ch
```

### Receiving Multiple Values with Range

```go
for v := range ch {
	fmt.Println(v)
}
```

This loop continues until the channel is closed.

### Directional Channels

You can restrict channels to send-only or receive-only.

```go
func sendData(ch chan<- int) {
	ch <- 10
}

func receiveData(ch <-chan int) {
	fmt.Println(<-ch)
}
```

This improves type safety.

---

## 7. Select Statement

The `select` statement waits on multiple channel operations and executes whichever is ready first.

Example:

```go
select {
case msg := <-ch1:
	fmt.Println("Received", msg)
case ch2 <- "data":
	fmt.Println("Sent data")
default:
	fmt.Println("No channel ready")
}
```

Use cases:

* Handling multiple goroutines
* Implementing timeouts
* Avoiding blocking

Timeout example:

```go
select {
case res := <-ch:
	fmt.Println(res)
case <-time.After(2 * time.Second):
	fmt.Println("Timeout!")
}
```

---

## 8. Closing Channels

Channels should be closed by the sender when no more data will be sent.

```go
close(ch)
```

Why close a channel?

* Signals receivers that no more values are coming.
* Prevents deadlocks in range loops.

Check if a channel is closed:

```go
value, ok := <-ch

if !ok {
	fmt.Println("Channel closed")
}
```

Important rules:

* Never close a channel from the receiver side.
* Never close a channel twice (causes panic).
* Only close when necessaryâ€”many channels donâ€™t need closing.

---

## 9. Use Cases for Goroutines and Channels

### Parallel Processing

Speed up CPU-bound tasks.

Examples:

* Image processing
* Data analysis
* Scientific computations

### Worker Pools

Limit concurrency while processing many jobs.

Pattern:

* Jobs channel
* Worker goroutines
* Results channel

### Pipelines

Break complex tasks into stages.

Example flow:

```
Generate Data â†’ Process Data â†’ Save Results
```

Each stage runs in separate goroutines connected by channels.

### Fan-Out / Fan-In

* **Fan-Out:** Multiple goroutines process the same input channel.
* **Fan-In:** Combine results into a single channel.

### Timeouts and Cancellation

Use `select` with `time.After` or `context` to avoid hanging goroutines.

### Real-Time Systems

Ideal for:

* Chat servers
* Streaming systems
* APIs handling thousands of requests
* Background job processors

---

## Best Practices

* Do not create excessive goroutines without control.
* Use channels instead of shared memory when possible.
* Avoid blocking operations inside goroutines unless necessary.
* Always consider race conditions (use `go run -race`).
* Prefer `context` for cancellation.
* Keep concurrency simpleâ€”complex patterns are harder to debug.

---

## Conclusion

Goroutines and channels form the backbone of Goâ€™s concurrency model. They allow developers to write highly scalable, efficient, and readable concurrent programs without dealing directly with the complexity of thread management.

Understanding how the scheduler works, when to use buffered vs unbuffered channels, and how to properly synchronize goroutines will help you design robust high-performance applications in Go.
